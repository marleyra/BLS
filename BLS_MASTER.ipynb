{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4aea493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed5f212",
   "metadata": {},
   "source": [
    "### 1. Load BLS raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f76b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['1990', '2000', '2010', '2020']\n",
    "NAICS = ['11', '21', '31', '51', '52', '54']\n",
    "files = []\n",
    "#NAICS5 = ['51121', '51821', '54151', '54161']\n",
    "\n",
    "# create list of desired file names, looping through year, BLS folder, and NAICS code\n",
    "for year in years:\n",
    "    folder = sorted(os.listdir('BLS_raw/' + year + '.annual.by_industry'))\n",
    "    for file in folder:\n",
    "        for code in NAICS:\n",
    "            if code + ' ' in file[12:15]:\n",
    "                files.append(file)\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab161e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df11_1990', 'df21_1990', 'df51_1990', 'df52_1990', 'df54_1990', 'df11_2000', 'df21_2000', 'df51_2000', 'df52_2000', 'df54_2000', 'df11_2010', 'df21_2010', 'df51_2010', 'df52_2010', 'df54_2010', 'df11_2020', 'df21_2020', 'df51_2020', 'df52_2020', 'df54_2020'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = []\n",
    " \n",
    "# loop through year and file to append dataframes into a list\n",
    "for year in years:\n",
    "    for file in files:\n",
    "        if year in file:\n",
    "            temp_df = pd.read_csv('BLS_raw/' + year + '.annual.by_industry/' + file)\n",
    "            mask_non50 = ((temp_df['area_fips'].str[-3:] == '000') | \n",
    "                          (temp_df['area_fips'].str[:1] == 'C') | \n",
    "                          (temp_df['area_fips'].str[:2] == 'US') | \n",
    "                          (temp_df['area_fips'].str[:1] == '7'))\n",
    "            temp_df = temp_df[~mask_non50] # apply Kurt's filter within loop\n",
    "            df_list.append(temp_df)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "# store dataframes in dictionary\n",
    "names = []\n",
    "for x in range(0, len(files)):\n",
    "    names.append('df' + files[x][12:14]+ '_' + files[x][:4])\n",
    "\n",
    "d = dict(zip(names, df_list))\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d11fcd",
   "metadata": {},
   "source": [
    "### 2. Process raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766bb25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1111, 43)\n",
      "(667, 43)\n",
      "(2197, 43)\n",
      "(3023, 43)\n",
      "(2440, 43)\n",
      "(1156, 43)\n",
      "(692, 43)\n",
      "(2301, 43)\n",
      "(3135, 43)\n",
      "(2755, 43)\n",
      "(3293, 43)\n",
      "(2523, 43)\n",
      "(5292, 43)\n",
      "(3975, 43)\n",
      "(4641, 43)\n",
      "(3299, 43)\n",
      "(2492, 43)\n",
      "(5199, 43)\n",
      "(3834, 43)\n",
      "(4733, 43)\n"
     ]
    }
   ],
   "source": [
    "# drop undefined counties\n",
    "for key in d.keys():\n",
    "    d[key] = d[key][d[key]['area_fips'].str[-3:] != '999']\n",
    "    print(d[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f315affb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1099, 3)\n",
      "(667, 3)\n",
      "(2061, 3)\n",
      "(2301, 3)\n",
      "(2003, 3)\n",
      "(1141, 3)\n",
      "(692, 3)\n",
      "(2086, 3)\n",
      "(2316, 3)\n",
      "(2097, 3)\n",
      "(3071, 3)\n",
      "(2515, 3)\n",
      "(3081, 3)\n",
      "(3130, 3)\n",
      "(3121, 3)\n",
      "(3091, 3)\n",
      "(2486, 3)\n",
      "(3066, 3)\n",
      "(3125, 3)\n",
      "(3122, 3)\n"
     ]
    }
   ],
   "source": [
    "# merge public and private sector employment within-county\n",
    "for key in d.keys():\n",
    "    d[key] = (d[key].groupby(by=['area_fips', 'area_title'], as_index=False)['annual_avg_emplvl'].sum())\n",
    "    print(d[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7e08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load typology (US Census geographical classifications) and regional data\n",
    "reg = pd.read_csv('typology/regions.csv')\n",
    "typ = pd.read_csv('typology/typology.csv')\n",
    "\n",
    "# change county codes to proper fips\n",
    "typ['fips'] = typ['fips'].astype(str).str.zfill(5)\n",
    "\n",
    "# merge BLS data with '03, '13, & '20' geographical classifications, retaining all counties from typ file\n",
    "for key in d.keys():\n",
    "    d[key] = d[key].merge(typ, how='right', left_on='area_fips', right_on='fips')\n",
    "\n",
    "# assign regions to BLS data\n",
    "for key in d.keys():\n",
    "    for k, v in dict(zip(reg.STATE, reg.REGION)).items():\n",
    "        d[key].loc[d[key]['State'] == k, ['region']] = v\n",
    "    d[key].loc[d[key]['area_title'] == 'District of Columbia', 'region'] = 'Mid-Atlantic' # give DC a region\n",
    "    \n",
    "# export selected columns\n",
    "final_cols = ['fips', 'County Title', 'State', 'region',\n",
    "              'type_census03', 'type_bls13', 'type_census20', 'type_kurt20',\n",
    "              'annual_avg_emplvl']\n",
    "\n",
    "for key in d.keys():\n",
    "    d[key][final_cols].to_csv('my_naics/naics_' + key[2:] + '.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a292411f",
   "metadata": {},
   "source": [
    "### 3. Calculate employment change columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dcda85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 (3169, 16)\n",
      "21 (3169, 16)\n",
      "51 (3169, 16)\n",
      "52 (3169, 16)\n",
      "54 (3169, 16)\n"
     ]
    }
   ],
   "source": [
    "# load new NAICS CSVs\n",
    "codes = ['11', '21', '51', '52', '54']\n",
    "path = 'my_naics/naics_'\n",
    "\n",
    "# use big loop to update all previously processed NAICS files\n",
    "for code in codes:\n",
    "    df90 = pd.read_csv(path + code + '_1990.csv')\n",
    "    df00 = pd.read_csv(path + code + '_2000.csv')\n",
    "    df10 = pd.read_csv(path + code + '_2010.csv')\n",
    "    df20 = pd.read_csv(path + code + '_2020.csv')\n",
    "    \n",
    "    # merge years under NAICS code\n",
    "    temp1 = df90.merge(df00, how='inner', left_on='fips', right_on='fips', suffixes=['_90', '_00'])\n",
    "    temp2 = df10.merge(df20, how='inner', left_on='fips', right_on='fips', suffixes=['_10', '_20'])\n",
    "    df = temp1.merge(temp2, how='inner', left_on='fips', right_on='fips')\n",
    "    \n",
    "    # clean column names\n",
    "    cols = df.columns.tolist()[:9]\n",
    "    for col in df.columns.tolist()[9:]:\n",
    "        if col[:-3] == 'annual_avg_emplvl':\n",
    "            cols.append(col)\n",
    "        else:\n",
    "            pass\n",
    "    df = df[cols]\n",
    "    df.columns = df.columns.str.replace('_90', '')\n",
    "    df = df.rename(columns={'annual_avg_emplvl': 'annual_avg_emplvl_90'})\n",
    "    \n",
    "    # replace nulls with zeroes \n",
    "    empl_cols = df.columns[-4:]\n",
    "    df[empl_cols] = df[empl_cols].fillna(0)\n",
    "\n",
    "    # rate of change function\n",
    "    def rate_chg(df, year1, year2, chg):\n",
    "        df[chg] = np.where((df[year1]== 0),\n",
    "                          ((df[year2] - df[year1]) / 1).round(4),\n",
    "                          ((df[year2] - df[year1]) / df[year1]).round(4))\n",
    "    \n",
    "    # define new column namer\n",
    "    namer = empl_cols.str.split('_')\n",
    "\n",
    "    # calculate rate of change\n",
    "    for x in range(0,3):\n",
    "        rate_chg(df, empl_cols[x], empl_cols[x+1], 'chg_' + namer[x][2] + '_' + namer[x][3] + '_' + namer[x+1][3])\n",
    "    \n",
    "    # calculate total rate of change column (1990-2020)\n",
    "    df['chg_emplvl_90_20'] = np.where((df['annual_avg_emplvl_90']==0),\n",
    "                                      ((df['annual_avg_emplvl_20'] - df['annual_avg_emplvl_90']) / 1).round(4),\n",
    "                                      ((df['annual_avg_emplvl_20'] - df['annual_avg_emplvl_90']) / df['annual_avg_emplvl_90']).round(4))\n",
    "    \n",
    "    # export file\n",
    "    print(code, df[df['County Title'].notna()].shape)\n",
    "    df[df['County Title'].notna()].to_csv('my_naics_chg/naics_' + code + '.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32183bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>County Title</th>\n",
       "      <th>State</th>\n",
       "      <th>region</th>\n",
       "      <th>type_census03</th>\n",
       "      <th>type_bls13</th>\n",
       "      <th>type_census20</th>\n",
       "      <th>type_kurt20</th>\n",
       "      <th>annual_avg_emplvl_90</th>\n",
       "      <th>annual_avg_emplvl_00</th>\n",
       "      <th>annual_avg_emplvl_10</th>\n",
       "      <th>annual_avg_emplvl_20</th>\n",
       "      <th>chg_emplvl_90_00</th>\n",
       "      <th>chg_emplvl_00_10</th>\n",
       "      <th>chg_emplvl_10_20</th>\n",
       "      <th>chg_emplvl_90_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>51933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Metro</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>51901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Metro</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>51947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Metro</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>15901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Metro</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>51953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Metro</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>72133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Micro</td>\n",
       "      <td>Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>72055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Metro</td>\n",
       "      <td>Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>72059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Metro</td>\n",
       "      <td>Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>72111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Metro</td>\n",
       "      <td>Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>72153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Metro</td>\n",
       "      <td>Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fips County Title State region type_census03 type_bls13 type_census20  \\\n",
       "3169  51933          NaN   NaN    NaN         Rural      Rural         Rural   \n",
       "3170  51901          NaN   NaN    NaN         Rural      Rural         Rural   \n",
       "3171  51947          NaN   NaN    NaN         Rural      Rural         Rural   \n",
       "3172  15901          NaN   NaN    NaN         Rural      Rural         Rural   \n",
       "3173  51953          NaN   NaN    NaN         Rural      Rural         Rural   \n",
       "...     ...          ...   ...    ...           ...        ...           ...   \n",
       "3259  72133          NaN   NaN    NaN         Rural      Rural         Micro   \n",
       "3260  72055          NaN   NaN    NaN         Rural      Rural         Metro   \n",
       "3261  72059          NaN   NaN    NaN         Rural      Rural         Metro   \n",
       "3262  72111          NaN   NaN    NaN         Rural      Rural         Metro   \n",
       "3263  72153          NaN   NaN    NaN         Rural      Rural         Metro   \n",
       "\n",
       "     type_kurt20  annual_avg_emplvl_90  annual_avg_emplvl_00  \\\n",
       "3169       Metro                   0.0                   0.0   \n",
       "3170       Metro                   0.0                   0.0   \n",
       "3171       Metro                   0.0                   0.0   \n",
       "3172       Metro                   0.0                   0.0   \n",
       "3173       Metro                   0.0                   0.0   \n",
       "...          ...                   ...                   ...   \n",
       "3259       Rural                   0.0                   0.0   \n",
       "3260       Rural                   0.0                   0.0   \n",
       "3261       Rural                   0.0                   0.0   \n",
       "3262       Rural                   0.0                   0.0   \n",
       "3263       Rural                   0.0                   0.0   \n",
       "\n",
       "      annual_avg_emplvl_10  annual_avg_emplvl_20  chg_emplvl_90_00  \\\n",
       "3169                   0.0                   0.0               0.0   \n",
       "3170                   0.0                   0.0               0.0   \n",
       "3171                   0.0                   0.0               0.0   \n",
       "3172                   0.0                   0.0               0.0   \n",
       "3173                   0.0                   0.0               0.0   \n",
       "...                    ...                   ...               ...   \n",
       "3259                   0.0                   0.0               0.0   \n",
       "3260                   0.0                   0.0               0.0   \n",
       "3261                   0.0                   0.0               0.0   \n",
       "3262                   0.0                   0.0               0.0   \n",
       "3263                   0.0                   0.0               0.0   \n",
       "\n",
       "      chg_emplvl_00_10  chg_emplvl_10_20  chg_emplvl_90_20  \n",
       "3169               0.0               0.0               0.0  \n",
       "3170               0.0               0.0               0.0  \n",
       "3171               0.0               0.0               0.0  \n",
       "3172               0.0               0.0               0.0  \n",
       "3173               0.0               0.0               0.0  \n",
       "...                ...               ...               ...  \n",
       "3259               0.0               0.0               0.0  \n",
       "3260               0.0               0.0               0.0  \n",
       "3261               0.0               0.0               0.0  \n",
       "3262               0.0               0.0               0.0  \n",
       "3263               0.0               0.0               0.0  \n",
       "\n",
       "[95 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['County Title'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "808a855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check on fips 15005 Kalawao County, so either ignore or treat as incl. in Maui\n",
    "for key in d.keys():\n",
    "    print(len(d[key][d[key]['fips'] == '15005']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beb1766",
   "metadata": {},
   "source": [
    "### 4. Incorporate spatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b09f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# load US counties SHP\n",
    "gdf_full = gpd.read_file('GIS Data/usa_census_counties_2018_20m/')\n",
    "gdf_full.set_index('GEOID', inplace=True)\n",
    "\n",
    "# drop non-continental columns (AK, HI, & PR)\n",
    "mask_non_continental = ((gdf_full['STATEFP'] == '02') | (gdf_full['STATEFP'] == '15') | (gdf_full['STATEFP'] == '72'))\n",
    "gdf_continental = gdf_full[~mask_non_continental]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e34727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NAICS files with change columns\n",
    "codes = ['11', '21', '51', '52', '54']\n",
    "path = 'my_naics_chg/naics_'\n",
    "\n",
    "for code in codes:\n",
    "    df = pd.read_csv(path + code + '.csv')\n",
    "    df['fips'] = df['fips'].astype(str).str.zfill(5)\n",
    "    df = df.set_index('fips')\n",
    "    \n",
    "    # merge with continental gdf\n",
    "    gdf = gdf_continental.merge(df, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    # export to shapefile\n",
    "    gdf.to_file('SHPs/NAICS', driver ='ESRI Shapefile')\n",
    "    \n",
    "    # SPATIAL ANALYSIS\n",
    "    for col in gdf.columns[20:]:\n",
    "        ax = gdf.plot(column=col, cmap='RdYlGn',\n",
    "                      edgecolor='lightgrey', linewidth=0.1,\n",
    "                      legend=True, legend_kwds={'shrink': 0.6},\n",
    "                      vmax=1, vmin=-1,\n",
    "                      figsize=(15,10),\n",
    "                      missing_kwds={'color': 'white', 'hatch': 'XXX',\n",
    "                                    'edgecolor': 'lightgrey', 'linewidth' : 0.2,\n",
    "                                    'label': 'Null or No Data'})\n",
    "    \n",
    "        title = 'NAICS ' + code + ' Industry Employment Dynamics ' + col[11:13] + '-' + col[14:]\n",
    "        ax.set_title(title, fontsize = 13)\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "        # save figure\n",
    "        ax.get_figure().savefig('maps/' + title, dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate code book for cluster analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ppd599)",
   "language": "python",
   "name": "ppd599"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
