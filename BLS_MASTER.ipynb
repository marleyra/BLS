{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e0bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d161d",
   "metadata": {},
   "source": [
    "### 1. Load BLS raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6551f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['1990', '2000', '2010', '2020']\n",
    "files = []\n",
    "#NAICS = ['51', '52', '54']\n",
    "NAICS = ['11', '21', '31', '51', '52', '54']\n",
    "#NAICS5 = ['51121', '51821', '54151', '54161']\n",
    "\n",
    "# create list of desired file names, looping through year, BLS folder, and NAICS code\n",
    "for year in years:\n",
    "    folder = sorted(os.listdir('BLS_raw/' + year + '.annual.by_industry'))\n",
    "    for file in folder:\n",
    "        for code in NAICS:\n",
    "            if code + ' ' in file[12:15]:\n",
    "                files.append(file)\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1fdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    " \n",
    "# loop through year and file to append dataframes into a list\n",
    "for year in years:\n",
    "    for file in files:\n",
    "        if year in file:\n",
    "            temp_df = pd.read_csv('BLS_raw/' + year + '.annual.by_industry/' + file)\n",
    "            mask_non50 = ((temp_df['area_fips'].str[-3:] == '000') | \n",
    "                          (temp_df['area_fips'].str[:1] == 'C') | \n",
    "                          (temp_df['area_fips'].str[:2] == 'US') | \n",
    "                          (temp_df['area_fips'].str[:1] == '7'))\n",
    "            temp_df = temp_df[~mask_non50] # apply Kurt's filter within loop\n",
    "            df_list.append(temp_df)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "# store dataframes in dictionary\n",
    "names = []\n",
    "for x in range(0, len(files)):\n",
    "    names.append('df' + files[x][12:14]+ '_' + files[x][:4])\n",
    "\n",
    "d = dict(zip(names, df_list))\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34911a9",
   "metadata": {},
   "source": [
    "### 2. Process raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac5ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop undefined counties\n",
    "for key in d.keys():\n",
    "    d[key] = d[key][d[key]['area_fips'].str[-3:] != '999']\n",
    "    print(d[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge public and private sector employment within-county\n",
    "for key in d.keys():\n",
    "    d[key] = (d[key].groupby(by=['area_fips', 'area_title'], as_index=False)['annual_avg_emplvl'].sum())\n",
    "    print(d[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7af2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load typology (US Census geographical classifications) and regional data\n",
    "reg = pd.read_csv('typology/regions.csv')\n",
    "typ = pd.read_csv('typology/typology.csv')\n",
    "\n",
    "# change county codes to proper fips\n",
    "typ['fips'] = typ['fips'].astype(str).str.zfill(5)\n",
    "\n",
    "# merge BLS data with '03, '13, & '20' geographical classifications, retaining all counties from typ file\n",
    "for key in d.keys():\n",
    "    d[key] = d[key].merge(typ, how='right', left_on='area_fips', right_on='fips')\n",
    "\n",
    "# assign regions to BLS data\n",
    "for key in d.keys():\n",
    "    for k, v in dict(zip(reg.STATE, reg.REGION)).items():\n",
    "        d[key].loc[d[key]['State'] == k, ['region']] = v\n",
    "    d[key].loc[d[key]['area_title'] == 'District of Columbia', 'region'] = 'Mid-Atlantic' # give DC a region\n",
    "    \n",
    "# export selected columns\n",
    "final_cols = ['fips', 'County Title', 'State', 'region',\n",
    "              'type_census03', 'type_bls13', 'type_census20', 'type_kurt20',\n",
    "              'annual_avg_emplvl']\n",
    "\n",
    "for key in d.keys():\n",
    "    d[key][final_cols].to_csv('my_naics/naics_' + key[2:] + '.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ab578",
   "metadata": {},
   "source": [
    "### 3. Calculate employment change columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load new NAICS CSVs\n",
    "codes = ['11', '21', '51', '52', '54']\n",
    "path = 'my_naics/naics_'\n",
    "\n",
    "# use big loop to update all previously processed NAICS files\n",
    "for code in codes:\n",
    "    df90 = pd.read_csv(path + code + '_1990.csv')\n",
    "    df00 = pd.read_csv(path + code + '_2000.csv')\n",
    "    df10 = pd.read_csv(path + code + '_2010.csv')\n",
    "    df20 = pd.read_csv(path + code + '_2020.csv')\n",
    "    \n",
    "    # merge years under NAICS code\n",
    "    temp1 = df90.merge(df00, how='inner', left_on='fips', right_on='fips', suffixes=['_90', '_00'])\n",
    "    temp2 = df10.merge(df20, how='inner', left_on='fips', right_on='fips', suffixes=['_10', '_20'])\n",
    "    df = temp1.merge(temp2, how='inner', left_on='fips', right_on='fips')\n",
    "    \n",
    "    # clean column names\n",
    "    cols = df.columns.tolist()[:9]\n",
    "    for col in df.columns.tolist()[9:]:\n",
    "        if col[:-3] == 'annual_avg_emplvl':\n",
    "            cols.append(col)\n",
    "        else:\n",
    "            pass\n",
    "    df = df[cols]\n",
    "    df.columns = df.columns.str.replace('_90', '')\n",
    "    df = df.rename(columns={'annual_avg_emplvl': 'annual_avg_emplvl_90'})\n",
    "    \n",
    "    # replace nulls with zeroes\n",
    "    empl_cols = df.columns[-4:]\n",
    "    df[empl_cols] = df[empl_cols].fillna(0)\n",
    "\n",
    "    # rate of change function\n",
    "    def rate_chg(df, year1, year2, chg):\n",
    "        df[chg] = np.where((df[year1]== 0),\n",
    "                          ((df[year2] - df[year1]) / 1).round(4),\n",
    "                          ((df[year2] - df[year1]) / df[year1]).round(4))\n",
    "    \n",
    "    # define new column namer\n",
    "    namer = empl_cols.str.split('_')\n",
    "\n",
    "    # calculate rate of change\n",
    "    for x in range(0,3):\n",
    "        rate_chg(df, empl_cols[x], empl_cols[x+1], 'chg_' + namer[x][2] + '_' + namer[x][3] + '_' + namer[x+1][3])\n",
    "    \n",
    "    # calculate total rate of change column (1990-2020)\n",
    "    df['chg_emplvl_90_20'] = np.where((df['annual_avg_emplvl_90']==0),\n",
    "                                      ((df['annual_avg_emplvl_20'] - df['annual_avg_emplvl_90']) / 1).round(4),\n",
    "                                      ((df['annual_avg_emplvl_20'] - df['annual_avg_emplvl_90']) / df['annual_avg_emplvl_90']).round(4))\n",
    "    \n",
    "    # export file\n",
    "    print(code, df.shape)\n",
    "    df.to_csv('my_naics_chg/naics_' + code + '.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a336e51e",
   "metadata": {},
   "source": [
    "### 4. Incorporate spatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290de670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# load US counties SHP\n",
    "gdf_full = gpd.read_file('GIS Data/usa_census_counties_2018_20m/')\n",
    "gdf_full.set_index('GEOID', inplace=True)\n",
    "\n",
    "# drop non-continental columns (AK, HI, & PR)\n",
    "mask_non_continental = ((gdf_full['STATEFP'] == '02') | (gdf_full['STATEFP'] == '15') | (gdf_full['STATEFP'] == '72'))\n",
    "gdf_continental = gdf_full[~mask_non_continental]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da7938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NAICS files with change columns\n",
    "codes = ['11', '21', '51', '52', '54']\n",
    "path = 'my_naics_chg/naics_'\n",
    "\n",
    "for code in codes:\n",
    "    df = pd.read_csv(path + code + '.csv')\n",
    "    \n",
    "    # merge with continental gdf\n",
    "    gdf = gdf_continental.merge(df, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    # export to shapefile\n",
    "    gdf.to_file('SHPs/NAICS', driver ='ESRI Shapefile')\n",
    "    \n",
    "    # SPATIAL ANALYSIS\n",
    "    ax = gdf.plot(column=col, cmap='RdYlGn',\n",
    "                  edgecolor='lightgrey', linewidth=0.1,\n",
    "                  legend=True, legend_kwds={'shrink': 0.6},\n",
    "                  vmax=100, vmin=-100,\n",
    "                  figsize=(15,10),\n",
    "                  missing_kwds={'color': 'white', 'hatch': 'XXX',\n",
    "                                'edgecolor': 'lightgrey', 'linewidth' : 0.2,\n",
    "                                'label': 'Null or No Data'})\n",
    "    \n",
    "    title = 'NAICS ' + gdf.name.strip('gdf') + ' Industry Employment Dynamics ' + col.strip('Growth Rate')\n",
    "    ax.set_title(title, fontsize = 13)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    # save figure\n",
    "    ax.get_figure().savefig('maps/' + maptitle, dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f1fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate code book for cluster analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ppd599)",
   "language": "python",
   "name": "ppd599"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
